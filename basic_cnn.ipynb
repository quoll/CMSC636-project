{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a1a15a-8f27-4926-b587-54d9f1222a94",
   "metadata": {},
   "source": [
    "# CMSC 636, Project: cheXpert analysis\n",
    "## Basic CNN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2356bcf0-47b5-4f89-9491-773bfe2700b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys              \n",
    "import json         \n",
    "import os               \n",
    "import argparse         \n",
    "import zipfile      \n",
    "import math         \n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from types import SimpleNamespace\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4d590-2829-45df-9b13-2d37cd9ca86a",
   "metadata": {},
   "source": [
    "# Setup constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77948dad-3a3b-43f8-bb84-178a041a9772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths will need to be setup on the host somwhere. These values provide overridable defaults\n",
    "default_label_file = 'label/findings_fixed.json'\n",
    "default_input_file = 'CheXpert-v1.0 batch 2 (train 1).zip'\n",
    "\n",
    "epochs = 10  # Number of epochs for training\n",
    "batch_size = 4  # Adjust based on your system's memory\n",
    "bounding_square = 2880 # Maximum image size we are prepared to consider. Larger will be scaled down\n",
    "image_ext = '.jpg'\n",
    "\n",
    "# cheXpert labels\n",
    "labels_in_order = [\"Enlarged Cardiomediastinum\", \"Cardiomegaly\", \"Lung Opacity\", \"Lung Lesion\",\n",
    "                   \"Edema\", \"Consolidation\", \"Pneumonia\", \"Atelectasis\",\n",
    "                   \"Pneumothorax\", \"Pleural Effusion\", \"Pleural Other\", \"Fracture\",\n",
    "                   \"Support Devices\", \"No Finding\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bcc1de-21a2-4f21-9fea-c744488533bd",
   "metadata": {},
   "source": [
    "# Load Data (from zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d960b3-fc3a-4d60-9c15-f7c7eec49a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_jpg_in_zip(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "        return sum(1 for name in zf.namelist() if name.endswith(image_ext))\n",
    "\n",
    "# pre-labeled data is in jpg format\n",
    "def jpg_from_zip_generator(zip_path, labels):\n",
    "    with zipfile.ZipFile(zip_path) as zf:\n",
    "        for name in zf.namelist():\n",
    "            if name.endswith(image_ext):\n",
    "                if name not in labels:\n",
    "                    print(f\"Warning: Found JPG '{name}' in zip but no corresponding label entry. Skipping.\")\n",
    "                    continue\n",
    "                with zf.open(name) as f:\n",
    "                    yield f.read(), labels[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1702fccd-0f5a-45a2-af03-c3812ff152ea",
   "metadata": {},
   "source": [
    "# Image Conformance\n",
    "All inputs to the model must be the same size, and the convolutions want square images.\n",
    "Selecting a large square that fits almost all images, and padding the shorter dimensions with black. The few images that are larger must be scaled down to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069b1318-a83d-40be-ba1e-ebdb02c99d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_fixed_size(image, target_size=(bounding_square, bounding_square)):\n",
    "    # Get original dimensions\n",
    "    current_height = tf.shape(image)[0]\n",
    "    current_width = tf.shape(image)[1]\n",
    "    \n",
    "    scale = tf.minimum(\n",
    "        target_size[0] / tf.cast(current_height, tf.float32),\n",
    "        target_size[1] / tf.cast(current_width, tf.float32)\n",
    "    )\n",
    "    \n",
    "    # scale down if it is too large\n",
    "    def resize_needed():\n",
    "        new_height = tf.cast(tf.cast(current_height, tf.float32) * scale, tf.int32)\n",
    "        new_width = tf.cast(tf.cast(current_width, tf.float32) * scale, tf.int32)\n",
    "        return tf.image.resize(image, [new_height, new_width], method='bilinear')\n",
    "    \n",
    "    def no_resize_needed():\n",
    "        return image\n",
    "    \n",
    "    # Only resize if the image is larger\n",
    "    image = tf.cond(\n",
    "        tf.logical_or(current_height > target_size[0], current_width > target_size[1]),\n",
    "        resize_needed,\n",
    "        no_resize_needed\n",
    "    )\n",
    "    \n",
    "    # Get dimensions after possible resize\n",
    "    current_height = tf.shape(image)[0]\n",
    "    current_width = tf.shape(image)[1]\n",
    "    \n",
    "    # Compute padding\n",
    "    pad_height = target_size[0] - current_height\n",
    "    pad_width = target_size[1] - current_width\n",
    "\n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "\n",
    "    padded = tf.pad(\n",
    "        image,\n",
    "        paddings=[[pad_top, pad_bottom], [pad_left, pad_right], [0,0]],\n",
    "        mode='CONSTANT',\n",
    "        constant_values=0\n",
    "    )\n",
    "    # The model needs to know the shape of the input tensor, so we set it explicitly here\n",
    "    padded.set_shape([bounding_square, bounding_square, 1])\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3946d3b8-8959-4b5a-9560-2f7e581d46f9",
   "metadata": {},
   "source": [
    "# Create the Dataset\n",
    "Use the defined functions to:\n",
    "- read the zip file\n",
    "- convert the jgp files to an image\n",
    "- pad (and occasionally scale down) the images\n",
    "- attach the labels to each image\n",
    "- convert to a \"generated\" dataset (so it does not reside in memory)\n",
    "\n",
    "Note that the `labels` argument is a dictionary of file path to the associated label vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe3a55-cfcc-43ef-8e5d-253d5204e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_from_zip(zip_path, labels):\n",
    "    length = count_jpg_in_zip(zip_path)\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: jpg_from_zip_generator(zip_path, labels),\n",
    "        output_types=(tf.string, tf.float32),  # output types of the generator\n",
    "        output_shapes=((), (len(labels_in_order),))\n",
    "    )\n",
    "    def pair_images_and_labels(x, y):\n",
    "        image = tf.image.convert_image_dtype(tf.io.decode_jpeg(x, channels=1), dtype=tf.float32)  # Decode the JPEG\n",
    "        return pad_to_fixed_size(image), y\n",
    "\n",
    "    dataset = dataset.map(pair_images_and_labels)\n",
    "    return dataset, length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74504210-9047-46c5-be27-21cbb406d513",
   "metadata": {},
   "source": [
    "# Create the label dictionary\n",
    "The `labels` dictionary is an unzipped text file of JSON lines. Each line is a single dictionary, containing the path of the image, and each of the image labels as either a `null` or a floating point value between 0.0 and 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8704e7-060d-46a3-ada0-148c54175389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_encoding(labels):\n",
    "    vector = []\n",
    "    for label in labels_in_order:\n",
    "        if label in labels:\n",
    "            value = labels[label]\n",
    "            if value is not None:\n",
    "                vector.append(value)\n",
    "            else:\n",
    "                vector.append(0.0)\n",
    "        else:\n",
    "            print(f\"Warning: Label '{label}' not found in the input data. Defaulting to 0.\")\n",
    "            vector.append(0.0)\n",
    "    # Return as a TensorFlow constant for compatibility with the dataset\n",
    "    return tf.constant(vector, dtype=tf.float32, shape=(len(labels_in_order),))\n",
    "\n",
    "def load_labels(label_file):\n",
    "    label_data = {}\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                entry = json.loads(line)\n",
    "                if 'path_to_image' in entry:\n",
    "                    path = entry['path_to_image']\n",
    "                    if path.startswith('train/'):\n",
    "                        path = path.replace('train/', 'CheXpert-v1.0 batch 2 (train 1)/', 1)\n",
    "                    elif path.startswith('valid/'):\n",
    "                        path = path.replace('valid/', 'CheXpert-v1.0 batch 2 (valid 1)/', 1)\n",
    "                    else:\n",
    "                        print(f\"Unexpected path format: {path}. Expected to start with 'train/'.\")\n",
    "                        continue\n",
    "                    # convert to an encoded vector for findings\n",
    "                    label_data[path] = vector_encoding(entry)\n",
    "                else:\n",
    "                    print(f\"Skipping entry without 'path_to_image' on line {f.tell()}: {entry}\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "                continue\n",
    "    return label_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00658f6-dcc6-4922-9985-fed24e36606b",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae32a362-2eb1-4b9d-a877-a4445b2f25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Input(shape=(bounding_square,bounding_square,1)),\n",
    "        Conv2D(64, (5,5), activation='relu', padding='valid'),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=2),\n",
    "\n",
    "        Conv2D(128, (5,5), activation='relu', padding='valid'),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=2),\n",
    "\n",
    "        Conv2D(256, (5,5), activation='relu', padding='valid'),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=2),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        # Dense(512, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        # Dropout(0.5),\n",
    "        Dense(14, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "                  loss=BinaryCrossentropy(),\n",
    "                  metrics=[BinaryAccuracy()])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf044c-ed79-45fd-89c0-388989c016b2",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc029ada-18d3-452d-a164-4700fdb5488a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_dataset(model, dataset, length, validate_dataset, vlength):\n",
    "    steps_per_epoch = math.ceil(length / batch_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat()  # Repeat the dataset for multiple epochs\n",
    "    validation_steps = math.ceil(vlength / batch_size)\n",
    "    validate_dataset = validate_dataset.batch(batch_size)\n",
    "\n",
    "    #time the epochs to see how long it takes to train\n",
    "    start_time = tf.timestamp()  # Start time for timing the training\n",
    "    model.fit(dataset,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_data=validate_dataset,\n",
    "              validation_steps=validation_steps)\n",
    "    end_time = tf.timestamp()  # End time for timing the training\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Training completed in {elapsed_time.numpy()} seconds.\")\n",
    "    # Save the model\n",
    "    model.save('model.h5')\n",
    "    print(\"Model saved as 'model.h5'.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc39e4a-1c09-41c2-9135-aa5bac894361",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9f6794-80a3-4f78-9c3e-56e234c1f1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = default_input_file\n",
    "label_file = default_label_file\n",
    "validate_file = default_validate_file\n",
    "\n",
    "# Load the labels. These are the labels for all data and validation files\n",
    "label_data = load_labels(label_file)\n",
    "\n",
    "# Load the images\n",
    "dataset, length = dataset_from_zip(input_file, label_data)\n",
    "print(f\"Total entries processed: {len(label_data)}\")\n",
    "\n",
    "dataset, length = dataset_from_zips(input_files, label_data)\n",
    "validate_dataset, vlength = dataset_from_zip(validate_file, label_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a67d91-f861-42f2-8544-c1998b653b5f",
   "metadata": {},
   "source": [
    "# Create the Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3549f8f6-dc1c-444f-9701-91e896fd106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model = process_dataset(model, dataset, length, validate_dataset, vlength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98939d22-522e-4dd4-935e-e8cd5d51ad82",
   "metadata": {},
   "source": [
    "# 4. Test the Model on the testing dataset\n",
    "\n",
    "This is still a TODO item"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
