{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a1a15a-8f27-4926-b587-54d9f1222a94",
   "metadata": {},
   "source": [
    "# CMSC 636, Project: cheXpert analysis\n",
    "## Basic CNN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2356bcf0-47b5-4f89-9491-773bfe2700b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from types import SimpleNamespace\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bcc1de-21a2-4f21-9fea-c744488533bd",
   "metadata": {},
   "source": [
    "# 1. Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d960b3-fc3a-4d60-9c15-f7c7eec49a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    x_train = x_train.astype(np.float32) / 255.0\n",
    "    x_test  = x_test.astype(np.float32) / 255.0\n",
    "\n",
    "    # Reshape to (batch, height, width, channels)\n",
    "    x_train = np.expand_dims(x_train, axis=-1)  # shape: (60000, 28, 28, 1)\n",
    "    x_test  = np.expand_dims(x_test, axis=-1)   # shape: (10000, 28, 28, 1)\n",
    "\n",
    "    # One-hot encode labels\n",
    "    y_train = to_categorical(y_train, num_classes=10)\n",
    "    y_test  = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf044c-ed79-45fd-89c0-388989c016b2",
   "metadata": {},
   "source": [
    "# 2. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc029ada-18d3-452d-a164-4700fdb5488a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 23:50:38.812008: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-04-01 23:50:38.812029: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2025-04-01 23:50:38.812034: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "2025-04-01 23:50:38.812048: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-04-01 23:50:38.812060: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(28,28,1)),\n",
    "    Conv2D(32, (5,5), activation='relu', padding='valid'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=2),\n",
    "\n",
    "    Conv2D(64, (5,5), activation='relu', padding='valid'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d84884-5b35-4f2f-af8d-99bc026e83b8",
   "metadata": {},
   "source": [
    "* `Input(shape=(28,28,1))`: Defines the shape of the input.\n",
    "* `Conv2D(32, (5,5), activation='relu', padding='valid')`: A single greyscale image = 1, 32 filters each producing an output, the filter for the input image being a 5x5 convolution, and a ReLU activation. Output will be 24x24.\n",
    "* `MaxPooling2D(pool_size=(2,2), strides=2)`: Pooling from the convolutional layer. Halves the size to 12x12.\n",
    "* `Conv2D(64, (5,5), activation='relu')`: 32 outputs of the previous layer. This layer has 64 filters to apply to this, each searching for their own features. The convolution at this layer is 5x5. Output will be 8x8. ReLU activation.\n",
    "* `MaxPooling2D(pool_size=(2,2), strides=2)`: Pooling from the convolutional layer. Halves the size to 4x4.\n",
    "* `Flatten()`: Reduces 4x4 over 64 filters (1024 elements) to a single dimension vector.\n",
    "* `Dense(256, activation='relu')`: A hidden layer. Input is the 1024 from the previous layer, and outputs 256 elements. ReLU was also defined.\n",
    "* `DenseLayer(10, activation='softmax')`: Output layer. Input is 256, output is 10. Softmax as the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28954c97-02d7-46b5-97ee-ed6dab48a4fe",
   "metadata": {},
   "source": [
    "# 3. Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "326cebae-c7a5-4de9-a8d6-9439aeec657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "              loss=CategoricalCrossentropy(),\n",
    "              metrics=[CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8cf85ea-8ba8-4854-9aec-f9e39820778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 5000\n",
    "summary_freq = 200\n",
    "n_test_log = 10\n",
    "epochs = 10\n",
    "\n",
    "batch_size= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc39e4a-1c09-41c2-9135-aa5bac894361",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9f6794-80a3-4f78-9c3e-56e234c1f1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a67d91-f861-42f2-8544-c1998b653b5f",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3549f8f6-dc1c-444f-9701-91e896fd106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 23:50:39.347449: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - categorical_accuracy: 0.8784 - loss: 0.3871 - val_categorical_accuracy: 0.9840 - val_loss: 0.0495\n",
      "Epoch 2/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - categorical_accuracy: 0.9822 - loss: 0.0577 - val_categorical_accuracy: 0.9848 - val_loss: 0.0506\n",
      "Epoch 3/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - categorical_accuracy: 0.9864 - loss: 0.0417 - val_categorical_accuracy: 0.9886 - val_loss: 0.0383\n",
      "Epoch 4/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - categorical_accuracy: 0.9890 - loss: 0.0356 - val_categorical_accuracy: 0.9899 - val_loss: 0.0351\n",
      "Epoch 5/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - categorical_accuracy: 0.9901 - loss: 0.0370 - val_categorical_accuracy: 0.9907 - val_loss: 0.0348\n",
      "Epoch 6/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - categorical_accuracy: 0.9916 - loss: 0.0306 - val_categorical_accuracy: 0.9890 - val_loss: 0.0487\n",
      "Epoch 7/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - categorical_accuracy: 0.9906 - loss: 0.0400 - val_categorical_accuracy: 0.9856 - val_loss: 0.0914\n",
      "Epoch 8/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - categorical_accuracy: 0.9915 - loss: 0.0464 - val_categorical_accuracy: 0.9885 - val_loss: 0.1016\n",
      "Epoch 9/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - categorical_accuracy: 0.9897 - loss: 0.0749 - val_categorical_accuracy: 0.9904 - val_loss: 0.1121\n",
      "Epoch 10/10\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - categorical_accuracy: 0.9923 - loss: 0.0650 - val_categorical_accuracy: 0.9858 - val_loss: 0.1869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x340818350>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9165e7-990d-4998-b213-dfeedd9c7e1c",
   "metadata": {},
   "source": [
    "# Reset and retrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98939d22-522e-4dd4-935e-e8cd5d51ad82",
   "metadata": {},
   "source": [
    "# 4. Test the training model on the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727f0bbd-b574-4e6e-8ce9-f0f6e9c65f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - categorical_accuracy: 0.9820 - loss: 0.2453\n",
      "Test accuracy: 98.58% | Test loss: 0.186865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Predicted class: 9\n",
      "Labeled: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x341bf4e90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.2%} | Test loss: {test_loss:.6}\")\n",
    "\n",
    "# For a single image\n",
    "i = np.random.randint(len(x_test))\n",
    "x_sample = x_test[i]\n",
    "y_sample = y_test[i]\n",
    "image = x_sample[np.newaxis, ...]\n",
    "pred = model.predict(image)\n",
    "print(\"Predicted class:\", pred.argmax())\n",
    "print(\"Labeled:\", y_sample.argmax())\n",
    "\n",
    "plt.imshow(np.squeeze(image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
